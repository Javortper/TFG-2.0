{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from keras.applications import VGG19, VGG16, Xception, InceptionV3\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom keras.models import Model\nfrom tensorflow import keras\nimport keras\nimport numpy as np\n\nMETRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n]\n\n\ndef generate_model(model, input_shape, fully_n=128, opt='sgd', lr=0.01): #,metrics=METRICS\n    \"\"\"Return a modelo from Keras\n      model: model name. \n      input_shape: input shape images.\n      fully_n: number of neurons of fully connected layer.\n      opt: optimizer.\n      lr: optimizer learning rate.\n      metrics: metrics to measure model performance.\n    \"\"\"\n\n    models = {'vgg19':VGG19(weights='imagenet', include_top=False, input_shape=input_shape),\n              'vgg16':VGG16(weights='imagenet', include_top=False, input_shape=input_shape),\n              'xception':Xception(weights='imagenet', include_top=False, input_shape=input_shape),\n              'inception':InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)}\n    \n    optimizer= {'sgd': keras.optimizers.SGD(learning_rate=lr),\n                'adam':keras.optimizers.Adam(learning_rate=lr),\n                'rmsprop':keras.optimizers.RMSprop(learning_rate=lr),\n                'adadelta': keras.optimizers.Adadelta(learning_rate=lr)}\n\n    print(\"CHOOSED OPTIMIZER:\", str(optimizer[opt]))\n    # create the base model\n    base_model = models[model]\n\n    # Add average and pooling layer\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    # Añade classifier layer\n    x = Dense(fully_n, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    # Output layer\n    predictions = Dense(units=1, activation='sigmoid')(x)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    for layer in model.layers:\n        layer.trainable = True\n\n    model.compile(optimizer[opt], loss='binary_crossentropy')\n    model.summary()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\nTRAIN_PATH = '../input/chest-xray-pneumonia/chest_xray/train'\nTEST_PATH = '../input/chest-xray-pneumonia/chest_xray/test'\nPATHS = [TRAIN_PATH, TEST_PATH]\nIMG_SIZE = (400 , 400)\nCOLOR = \"rgb\"\nBATCH_S = 16\nCLASS_M = 'binary'\n\ndef create_generators(paths, img_size, color, batch_s, class_m, seed=1):  \n    \"\"\" Return ImageDataGenerators from a path.\n      paths: training and test folder path.\n      img_size: new images shape.\n      batch_s: batch size.\n      class_m: binary o categorical for one or more classes.\n      seed: remove randomness.\n    \"\"\"\n    #ImageDataGenerator \n    train_datagen = ImageDataGenerator(rescale=1./255)\n    test_datagen = ImageDataGenerator(rescale=1./255)\n    valid_datagen = ImageDataGenerator(rescale=1./255)\n\n    # Training generator\n    train_generator = train_datagen.flow_from_directory(directory=paths[0],\n                                                        target_size=img_size,\n                                                        color_mode=color,\n                                                        batch_size=batch_s,\n                                                        class_mode=class_m,\n                                                        shuffle=True,\n                                                        seed=seed)\n  \n    # Test generator\n    test_generator = test_datagen.flow_from_directory(directory=paths[1],\n                                                      target_size=img_size,\n                                                      color_mode=color,\n                                                      batch_size=batch_s,\n                                                      class_mode=class_m,\n                                                      shuffle=False)\n    \n  \n    return train_generator, test_generator\n\n\n\ndef create_generators_DA(paths, img_size, color, batch_s, class_m, seed=1):  \n    \"\"\" Return ImageDataGenerators from a path using Data Generator.\n      paths: training and test folder path.\n      img_size: new images shape.\n      batch_s: batch size.\n      class_m: binary o categorical for one or more classes.\n      seed: remove randomness.\n    \"\"\"\n    #ImageDataGenerator using Data Augmentation\n    train_datagen_DA = ImageDataGenerator(\n        rescale=1. / 255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        brightness_range=[0.5, 1.5])\n\n    train_generator_DA = train_datagen_DA.flow_from_directory(\n      directory=paths[0],\n      target_size=img_size,\n      color_mode=color,\n      batch_size=batch_s,\n      class_mode=class_m,\n      shuffle=True,\n      seed=seed)\n\n    return train_generator_DA\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, roc_curve\n\ndef conf_matrix(model, identifier):\n    model_name = identifier.split('_')[0]\n    true_labels = test_generator.classes.tolist()\n\n    test_generator.reset()\n    # Generate predictions array\n    predicted_labels = np.squeeze(model.predict_generator(test_generator))\n    predicted_labels = [1 if prediccion>=0.5 else 0 for prediccion in predicted_labels]\n\n    cm = confusion_matrix(true_labels, predicted_labels)\n\n    plt.style.use('seaborn-ticks')\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    ax.figure.colorbar(im, ax=ax)\n    ax.set(xticks=np.arange(cm.shape[1]),\n         yticks=np.arange(cm.shape[0]),\n         xticklabels=['Normal', 'Pneumonia'], yticklabels=['Normal', 'Pneumonia'],\n         title=identifier,\n         ylabel='Valor verdadero',\n         xlabel='Predicción')\n\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n           rotation_mode=\"anchor\")\n\n    fmt = '.0f' \n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    plt.savefig(('{}_MatrizConfusion.png').format(identifier), dpi=300)\n    plt.show()\n    return cm\n\n    \ndef plot_roc_curve(identifier, fpr, tpr, label=None):\n    model_name = identifier.split('_')[0]\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0,1], [0,1], 'k--') \n    plt.grid(True)\n    plt.xlabel('Falsos positivos [%]')\n    plt.ylabel('Verdaderos positivos (Recall) [%]')\n    plt.savefig(('{}_plot_ROC.png').format(identifier), dpi=300)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import f1_score\nimport time\n\n# Clase para medir la duración de cada epoch\nclass TimeHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.times = []\n        self.total_time = 0\n    def on_epoch_begin(self, batch, logs={}):\n        self.epoch_time_start = time.time()\n\n    def on_epoch_end(self, batch, logs={}):\n        self.times.append(time.time() - self.epoch_time_start)\n        self.total_time += time.time() - self.epoch_time_start\n\n\ndef train_and_save(opt,  model_name, lr, epochs, train_generator, test_generator, input_shape = None, fully_n=None,  weights=None):\n    time_callback = TimeHistory()\n    model = generate_model(model_name, input_shape = input_shape, fully_n = fully_n, opt=opt, lr=lr)\n    identifier =  '{}_{}_{}_{}'.format(model_name, epochs, opt, lr) \n    print(\"Model: {}.\\nNumber of epochs: {}. \\nOptimizer: {}\\nLearning rate: {}\".format(model_name, epochs, opt, lr))\n    \n    # Model train\n    history = train(model, train_generator, epochs, val_gen=test_generator, weights=weights) #, callbacks=[time_callback]\n    \n    # Printing metrics\n    test_generator.reset()\n    #baseline_results = model.evaluate_generator(test_generator, verbose=0)\n    #for name, value in zip(model.metrics_names, baseline_results):\n    #      print(name, ': ', value)\n\n    # Calculating F1-Score\n    #test_generator.reset()\n    #Y_test =  test_generator.classes.tolist()\n    #Y_pred = model.predict_generator(test_generator)\n    #Y_pred_class = [1 if i[0] >=0.5 else 0 for i in Y_pred]\n    #f1 = f1_score(Y_test, Y_pred_class)\n    #print(\"f1-score: \", f1)\n    \n    # Plot metrics\n    #plot_metrics(history, identifier)\n    \n    # Matrix confussion and ROC\n    #colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n    #conf_matrix(model, identifier)\n    \n    #fpr, tpr, thresholds = roc_curve(Y_test, Y_pred)\n    #plot_roc_curve(identifier, fpr, tpr)\n    #plt.show()\n\n    #Save history as np object\n    #np.save('{}_acc.npy'.format(identifier), history.history['val_accuracy'])\n    #np.save('{}_recall.npy'.format(identifier), history.history['val_recall'])\n    #np.save('{}_precision.npy'.format(identifier), history.history['val_precision'])\n    #np.save('{}_AUC.npy'.format(identifier), history.history['val_auc'])\n\n    #Save training in csv file\n    #csv_columns = [\"Modelo\",\"Optimizador\", \"Tasa de aprendizaje\", \"Duración del entrenamiento\", \"Pérdida\", \"Precisión\", \"Recall\", \"AUC\", \"Tasa de aciertos\", \"Puntuación F1\"]\n    #results_df = pd.DataFrame(columns=csv_columns)\n    #results_df.loc[len(results_df)] = [\n    #    model_name,\n    #    opt,\n    #    lr,\n    #    \"{} s\".format(str(int(time_callback.total_time))),\n    #    round(baseline_results[0], 3),\n    #    round(baseline_results[6], 3),\n    #    round(baseline_results[7], 3),\n    #    round(baseline_results[8], 3),\n    #    round(baseline_results[5],3),\n    #    round(f1,3)\n    #]\n    #results_df.to_csv('{}_df.csv'.format(identifier), index=False, encoding='utf-8-sig')\n\n    # Save weights\n    model.save('{}.h5'.format(identifier))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_metrics(history, identifier):\n    \"\"\"Plot loss, auc, precision and recall metrics and save it as png file\n    history: History. training history.\n    identifier: String. \n    \"\"\"\n    model_name = identifier.split('_')[0]\n    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n    metrics =  ['loss', 'auc', 'precision', 'recall']\n    plt.figure(figsize=(11, 9))\n    for n, metric in enumerate(metrics):\n        name = metric.replace(\"_\",\" \").capitalize()\n        plt.subplot(2,2,n+1)\n        plt.plot(history.epoch, history.history[metric], color=colors[0], label='Entrenamiento')\n        plt.plot(history.epoch, history.history['val_'+metric],\n                 color=colors[0], linestyle=\"--\", label='Validación')\n        plt.xlabel('Epoch')\n        plt.ylabel(name)\n        if metric == 'loss':\n            plt.ylim([0, plt.ylim()[1]])\n        elif metric == 'auc':\n            plt.ylim([0.8,1])\n        else:\n            plt.ylim([0,1])\n\n        plt.legend()\n    plt.tight_layout()\n    plt.savefig(('{}_plot_metricas.png').format(identifier), dpi=300)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, tr_gen, epochs, val_gen=None,callbacks=None ,weights=None):\n    \"\"\"Train a model.\n    model: model that will be trained.\n    tr_gen: train generator.\n    epochs: number of iterations.\n    val_gen: Generator to test the model every epoch.\n    callbacks: Callback Keras.\n    weights: wieght for each class.\n    \"\"\"\n    hist = model.fit_generator(\n            tr_gen,\n            epochs=epochs,\n            verbose=1,\n            validation_data=val_gen,\n            callbacks=callbacks,\n            class_weight=weights)\n    return hist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Entrenamiento básico"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training parameters\nopt = 'adam' # sgd, adam, adadelta, rmsprop\nlr = 0.0001 #0.01, 0.001, 0.0001\nepochs = 10\nmodel = 'inception'\n\nINPUT_SHAPE = (400, 400, 3)\ntrain_generator, test_generator = create_generators(PATHS, IMG_SIZE,\n                                                    COLOR, BATCH_S,\n                                                    CLASS_M)  #\n\ntrain_and_save(opt,\n             model,\n             train_generator,\n             test_generator,\n             input_shape = INPUT_SHAPE,\n             fully_n = 256)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training parameters\nopt = 'sgd' # sgd, adam, adadelta, rmsprop\nlr = 0.001 #0.01, 0.001, 0.0001\nepochs = 2\nmodel = 'vgg16'\n\nINPUT_SHAPE = (400, 400, 3)\ntrain_generator_DA = create_generators_DA(PATHS, IMG_SIZE,\n                                      COLOR, BATCH_S,\n                                      CLASS_M)  #\n\n_,test_generator = create_generators(PATHS, IMG_SIZE,\n                                   COLOR, BATCH_S,\n                                   CLASS_M)  \n\n\ntrain_and_save(opt,\n             model,\n             lr,\n             epochs,\n             train_generator_DA,\n             test_generator,\n             input_shape = INPUT_SHAPE,\n             fully_n = 256)\ntest_generator.reset()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DA + Pesos"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import class_weight\n# Training parameters\nopt = 'rmsprop' #adam, adadelta, rmsprop\nlr = 0.0001 #0.01, 0.001, 0.0001\nepochs = 10\nmodel = 'inception'\n\nINPUT_SHAPE = (400, 400, 3)\ntrain_generator_DA = create_generators_DA(PATHS, IMG_SIZE,\n                                       COLOR, BATCH_S,\n                                       CLASS_M)  \n\n_,test_generator = create_generators(PATHS, IMG_SIZE,\n                                    COLOR, BATCH_S,\n                                    CLASS_M)  \n\n# Generating weights\ntrue_labels = test_generator.classes.tolist()\nclass_weight = class_weight.compute_class_weight('balanced',\n                                                 np.unique(train_generator_DA.classes),\n                                                 true_labels)\n\n# Convertin weigths to dict (Keras requiriment)\nclass_weight_dict = dict()\nfor clas, weight in zip(np.unique(train_generator_DA.classes), class_weight):\n      class_weight_dict[clas] = weight\n  \nprint(\"Choosed weigths: \", class_weight_dict)\n\n\n\ntrain_and_save(opt,\n              model,\n              lr,\n              epochs,\n              train_generator_DA,\n              test_generator,\n              input_shape = INPUT_SHAPE,\n              fully_n = 256,\n              weights = class_weight_dict)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}